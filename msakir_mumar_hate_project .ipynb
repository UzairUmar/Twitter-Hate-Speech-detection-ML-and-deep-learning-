{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "msakir_mumar_hate_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhad_RhKVRa8"
      },
      "source": [
        "## Twitter Hate Speech Detection-Project Notebook\n",
        "Notebook Contributors: mumar, \n",
        "msakir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQeHSGkRKxSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9553fa-1970-48a5-d478-68c168f072e4"
      },
      "source": [
        "!pip install tweet-preprocessor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybucZ2FA6jZ_",
        "outputId": "2333a39e-2363-4c3e-db6d-68d7c9f188c8"
      },
      "source": [
        "!pip install demoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting demoji\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/fd/265f1ad2d745d6f46d1ede83d0054327e87154e9f14b252c1e272749e657/demoji-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from demoji) (2.23.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n",
            "Installing collected packages: colorama, demoji\n",
            "Successfully installed colorama-0.4.4 demoji-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E82DbajNJ-CA"
      },
      "source": [
        "import pandas as pd \n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import preprocessor as p\n",
        "import string\n",
        "from textblob import TextBlob\n",
        "import demoji\n",
        "import re\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUjmfyy0J-CB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2636a095-da3e-42dc-f96f-630893d3f5ff"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb4mnqTj1tpd",
        "outputId": "6f1469f6-2807-4023-c31c-25aba3d4be25"
      },
      "source": [
        "nltk.download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all\n",
            "    Downloading collection 'all'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Unzipping corpora/alpino.zip.\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Unzipping corpora/biocreative_ppi.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown.zip.\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown_tei.zip.\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_cat.zip.\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_esp.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/comparative_sentences.zip.\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Unzipping corpora/crubadan.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Unzipping corpora/dolch.zip.\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Unzipping corpora/europarl_raw.zip.\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Unzipping corpora/floresta.zip.\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v15.zip.\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v17.zip.\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Unzipping corpora/indian.zip.\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Unzipping corpora/kimmo.zip.\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Unzipping corpora/lin_thesaurus.zip.\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Unzipping corpora/mac_morpho.zip.\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Unzipping models/moses_sample.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       |   Unzipping corpora/omw.zip.\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Unzipping corpora/opinion_lexicon.zip.\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Unzipping corpora/paradigms.zip.\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Unzipping corpora/pil.zip.\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Unzipping corpora/pl196x.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Unzipping corpora/problem_reports.zip.\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Unzipping corpora/ptb.zip.\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_1.zip.\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_2.zip.\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Unzipping corpora/pros_cons.zip.\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Unzipping corpora/qc.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Unzipping corpora/rte.zip.\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentiwordnet.zip.\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentence_polarity.zip.\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/sinica_treebank.zip.\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Unzipping corpora/smultron.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Unzipping corpora/subjectivity.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Unzipping corpora/switchboard.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet.zip.\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet3.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet.zip.\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Unzipping corpora/ycoe.zip.\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Unzipping stemmers/rslp.zip.\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Unzipping taggers/universal_tagset.zip.\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/sample_grammars.zip.\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/spanish_grammars.zip.\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/basque_grammars.zip.\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/large_grammars.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Unzipping models/word2vec_sample.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Unzipping corpora/mte_teip5.zip.\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Unzipping misc/perluniprops.zip.\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Unzipping stemmers/porter_test.zip.\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Unzipping models/wmt15_eval.zip.\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Unzipping misc/mwa_ppdb.zip.\n",
            "       | \n",
            "     Done downloading collection all\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICK6GhJp7HxW",
        "outputId": "7ce8ed4b-4076-4bd3-fa81-d81ecd96b287"
      },
      "source": [
        "demoji.download_codes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading emoji data ...\n",
            "... OK (Got response in 0.09 seconds)\n",
            "Writing emoji data to /root/.demoji/codes.json ...\n",
            "... OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMbSiPttKbAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f87d9a64-e620-41e8-db3c-e887f5e0ebdf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzJaqmlT4g4G"
      },
      "source": [
        "# Shallow Machine Learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fC_zU60J-CD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "3f8b871f-553a-41cd-f7aa-ba737088d8cc"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Project/hate_speech_data/train_tweets.csv\")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>31958</td>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>31959</td>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>31960</td>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>31961</td>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>31962</td>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  label                                              tweet\n",
              "0          1      0   @user when a father is dysfunctional and is s...\n",
              "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2          3      0                                bihday your majesty\n",
              "3          4      0  #model   i love u take with u all the time in ...\n",
              "4          5      0             factsguide: society now    #motivation\n",
              "...      ...    ...                                                ...\n",
              "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
              "31958  31959      0    to see nina turner on the airwaves trying to...\n",
              "31959  31960      0  listening to sad songs on a monday morning otw...\n",
              "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
              "31961  31962      0                   thank you @user for you follow  \n",
              "\n",
              "[31962 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxzRRZ0iShgs"
      },
      "source": [
        "Deleting the ID column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Wl-PXvPCJ-CD",
        "outputId": "239e5f72-32be-4d14-ee5c-b5ee88743004"
      },
      "source": [
        "del df['id']\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                              tweet\n",
              "0          0   @user when a father is dysfunctional and is s...\n",
              "1          0  @user @user thanks for #lyft credit i can't us...\n",
              "2          0                                bihday your majesty\n",
              "3          0  #model   i love u take with u all the time in ...\n",
              "4          0             factsguide: society now    #motivation\n",
              "...      ...                                                ...\n",
              "31957      0  ate @user isz that youuu?ðððððð...\n",
              "31958      0    to see nina turner on the airwaves trying to...\n",
              "31959      0  listening to sad songs on a monday morning otw...\n",
              "31960      1  @user #sikh #temple vandalised in in #calgary,...\n",
              "31961      0                   thank you @user for you follow  \n",
              "\n",
              "[31962 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sW2mTQy0J-CD",
        "outputId": "0c027318-43df-44a3-995a-08052ac42a81"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>31962.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.070146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.255397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              label\n",
              "count  31962.000000\n",
              "mean       0.070146\n",
              "std        0.255397\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        0.000000\n",
              "max        1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB64PR5VSt6A"
      },
      "source": [
        "Converting Emoji to Text format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EZZH-DW8B1b"
      },
      "source": [
        "def repEmoji(text):\n",
        "  emoji = demoji.findall(text)\n",
        "  for emotes, tex in emoji.items():\n",
        "    text.replace(emotes, tex)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "kHZi8SR69TCk",
        "outputId": "788b5ab5-6e2c-46a9-8a15-551cbe1f104e"
      },
      "source": [
        "df['cleaned'] = df['tweet'].apply(repEmoji)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                            cleaned\n",
              "0          0  ...   @user when a father is dysfunctional and is s...\n",
              "1          0  ...  @user @user thanks for #lyft credit i can't us...\n",
              "2          0  ...                                bihday your majesty\n",
              "3          0  ...  #model   i love u take with u all the time in ...\n",
              "4          0  ...             factsguide: society now    #motivation\n",
              "...      ...  ...                                                ...\n",
              "31957      0  ...  ate @user isz that youuu?ðððððð...\n",
              "31958      0  ...    to see nina turner on the airwaves trying to...\n",
              "31959      0  ...  listening to sad songs on a monday morning otw...\n",
              "31960      1  ...  @user #sikh #temple vandalised in in #calgary,...\n",
              "31961      0  ...                   thank you @user for you follow  \n",
              "\n",
              "[31962 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvyW8rV0TAFk"
      },
      "source": [
        "Cleaning tweets using Tweet-preprocess library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "H-ospfyHJ-CD",
        "outputId": "820bd7d9-0c8c-4397-ee73-0749a678b95f"
      },
      "source": [
        "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED, p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.NUMBER)\n",
        "df['cleaned'] = df['cleaned'].apply(p.clean)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so selfi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for #lyft credit i can't use cause they...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model i love u take with u all the time in ur!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate isz that youuu?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>to see nina turner on the airwaves trying to w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>#sikh #temple vandalised in in #calgary, #wso ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank you for you follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                            cleaned\n",
              "0          0  ...  when a father is dysfunctional and is so selfi...\n",
              "1          0  ...  thanks for #lyft credit i can't use cause they...\n",
              "2          0  ...                                bihday your majesty\n",
              "3          0  ...  #model i love u take with u all the time in ur!!!\n",
              "4          0  ...                factsguide: society now #motivation\n",
              "...      ...  ...                                                ...\n",
              "31957      0  ...                                ate isz that youuu?\n",
              "31958      0  ...  to see nina turner on the airwaves trying to w...\n",
              "31959      0  ...  listening to sad songs on a monday morning otw...\n",
              "31960      1  ...  #sikh #temple vandalised in in #calgary, #wso ...\n",
              "31961      0  ...                           thank you for you follow\n",
              "\n",
              "[31962 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdDF13EUtm7N"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\", \"ive\": \"i have\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GApboSflTIl7"
      },
      "source": [
        "selfProcess(text) removes # symbol, converts words to their contracted form and removes single letters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rddCG87BuSc3"
      },
      "source": [
        "def selfPreprocess(text):\n",
        "  tok = text.split()\n",
        "  for i in range(0, len(tok)):\n",
        "    if tok[i][0] == '#':\n",
        "      new = tok[i][1:]\n",
        "      tok[i] = new \n",
        "  \n",
        "  contr = [contraction_mapping[w] if w in contraction_mapping.keys() else w for w in tok]\n",
        "\n",
        "  sent = ' '.join(contr)\n",
        "  reTok = sent.split()\n",
        "  noSingle = [word for word in reTok if len(word)>1]\n",
        "\n",
        "  return ' '.join(noSingle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "PWu_FxmjQkLn",
        "outputId": "80a6cb40-56d2-4ac2-bda6-dd5a85c446d0"
      },
      "source": [
        "df['cleaned'] = df['cleaned'].apply(selfPreprocess)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take with all the time in ur!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate isz that youuu?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>to see nina turner on the airwaves trying to w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening to sad songs on monday morning otw t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>sikh temple vandalised in in calgary, wso cond...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank you for you follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                            cleaned\n",
              "0          0  ...  when father is dysfunctional and is so selfish...\n",
              "1          0  ...  thanks for lyft credit cannot use cause they d...\n",
              "2          0  ...                                bihday your majesty\n",
              "3          0  ...         model love take with all the time in ur!!!\n",
              "4          0  ...                 factsguide: society now motivation\n",
              "...      ...  ...                                                ...\n",
              "31957      0  ...                                ate isz that youuu?\n",
              "31958      0  ...  to see nina turner on the airwaves trying to w...\n",
              "31959      0  ...  listening to sad songs on monday morning otw t...\n",
              "31960      1  ...  sikh temple vandalised in in calgary, wso cond...\n",
              "31961      0  ...                           thank you for you follow\n",
              "\n",
              "[31962 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yRcUn-XJ-CD"
      },
      "source": [
        "def countWords(text):\n",
        "    tok = text.split()\n",
        "    return len(tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4ly18kXJ-CD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "36f3f07c-aa19-4162-dcc5-65a455cfa148"
      },
      "source": [
        "df['word_count'] = df['cleaned'].apply(countWords)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take with all the time in ur!!!</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now motivation</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate isz that youuu?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>to see nina turner on the airwaves trying to w...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening to sad songs on monday morning otw t...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>sikh temple vandalised in in calgary, wso cond...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank you for you follow</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ... word_count\n",
              "0          0  ...         16\n",
              "1          0  ...         17\n",
              "2          0  ...          3\n",
              "3          0  ...          9\n",
              "4          0  ...          4\n",
              "...      ...  ...        ...\n",
              "31957      0  ...          4\n",
              "31958      0  ...         22\n",
              "31959      0  ...         12\n",
              "31960      1  ...          9\n",
              "31961      0  ...          5\n",
              "\n",
              "[31962 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjyKx6jsJ-CE"
      },
      "source": [
        "def uniqWordCount(text):\n",
        "    tok = text.split()\n",
        "    uniq = set(tok)\n",
        "    return len(uniq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G0Rfpc1J-CE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "9cbe9dc3-be28-44a2-9701-4dfeba1c82bc"
      },
      "source": [
        "df['unique_words_count'] = df['cleaned'].apply(uniqWordCount)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>word_count</th>\n",
              "      <th>unique_words_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take with all the time in ur!!!</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now motivation</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate isz that youuu?</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>to see nina turner on the airwaves trying to w...</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening to sad songs on monday morning otw t...</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>sikh temple vandalised in in calgary, wso cond...</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank you for you follow</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ... unique_words_count\n",
              "0          0  ...                 14\n",
              "1          0  ...                 17\n",
              "2          0  ...                  3\n",
              "3          0  ...                  9\n",
              "4          0  ...                  4\n",
              "...      ...  ...                ...\n",
              "31957      0  ...                  4\n",
              "31958      0  ...                 20\n",
              "31959      0  ...                 10\n",
              "31960      1  ...                  8\n",
              "31961      0  ...                  4\n",
              "\n",
              "[31962 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jEXXX-yZqda"
      },
      "source": [
        "def remStop(text):\n",
        "  stop = stopwords.words('english')\n",
        "  tok = text.split()\n",
        "  noStop = [word for word in tok if word not in stop]\n",
        "  return ' '.join(noStop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "Ean1O_t9iApC",
        "outputId": "2443d402-0dc7-4f35-8ac4-be40dc81f602"
      },
      "source": [
        "df['cleaned'] = df['cleaned'].apply(remStop)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>word_count</th>\n",
              "      <th>unique_words_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks lyft credit cannot use cause offer whee...</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday majesty</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take time ur!!!</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society motivation</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate isz youuu?</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>see nina turner airwaves trying wrap mantle ge...</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening sad songs monday morning otw work sad</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>sikh temple vandalised calgary, wso condemns act</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank follow</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ... unique_words_count\n",
              "0          0  ...                 14\n",
              "1          0  ...                 17\n",
              "2          0  ...                  3\n",
              "3          0  ...                  9\n",
              "4          0  ...                  4\n",
              "...      ...  ...                ...\n",
              "31957      0  ...                  4\n",
              "31958      0  ...                 20\n",
              "31959      0  ...                 10\n",
              "31960      1  ...                  8\n",
              "31961      0  ...                  4\n",
              "\n",
              "[31962 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14chFTCHQ-IE"
      },
      "source": [
        "def punCount(text):\n",
        "  tok = text.split()\n",
        "  count = 0\n",
        "  for word in tok:\n",
        "    for char in word:\n",
        "      if char in string.punctuation:\n",
        "        count += 1\n",
        "  return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "NGl6U3-DShhY",
        "outputId": "9e0e9259-fb9d-46ac-d54a-c56cafed485d"
      },
      "source": [
        "df['puntuation_count'] = df['cleaned'].apply(punCount)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>word_count</th>\n",
              "      <th>unique_words_count</th>\n",
              "      <th>puntuation_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks lyft credit cannot use cause offer whee...</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday majesty</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take time ur!!!</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society motivation</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate isz youuu?</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>see nina turner airwaves trying wrap mantle ge...</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening sad songs monday morning otw work sad</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>sikh temple vandalised calgary, wso condemns act</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank follow</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ... puntuation_count\n",
              "0          0  ...                1\n",
              "1          0  ...                1\n",
              "2          0  ...                0\n",
              "3          0  ...                3\n",
              "4          0  ...                1\n",
              "...      ...  ...              ...\n",
              "31957      0  ...                1\n",
              "31958      0  ...                1\n",
              "31959      0  ...                0\n",
              "31960      1  ...                1\n",
              "31961      0  ...                0\n",
              "\n",
              "[31962 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "we3chkpEFB77",
        "outputId": "e7185615-a7d6-4b3f-84cf-8d61518d86b2"
      },
      "source": [
        "df['polarity'] = df['cleaned'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>word_count</th>\n",
              "      <th>unique_words_count</th>\n",
              "      <th>puntuation_count</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks lyft credit cannot use cause offer whee...</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday majesty</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take time ur!!!</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0.976562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society motivation</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate isz youuu?</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>see nina turner airwaves trying wrap mantle ge...</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening sad songs monday morning otw work sad</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>sikh temple vandalised calgary, wso condemns act</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank follow</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...  polarity\n",
              "0          0  ... -0.500000\n",
              "1          0  ...  0.200000\n",
              "2          0  ...  0.000000\n",
              "3          0  ...  0.976562\n",
              "4          0  ...  0.000000\n",
              "...      ...  ...       ...\n",
              "31957      0  ...  0.000000\n",
              "31958      0  ...  0.400000\n",
              "31959      0  ... -0.500000\n",
              "31960      1  ...  0.000000\n",
              "31961      0  ...  0.000000\n",
              "\n",
              "[31962 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T721cs0OJ-CE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "1d9d2620-735e-46af-fc1f-93dbbd33b0f6"
      },
      "source": [
        "df['POS_tagged'] = nltk.pos_tag_sents(df['cleaned'].apply(nltk.word_tokenize).tolist())\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>word_count</th>\n",
              "      <th>unique_words_count</th>\n",
              "      <th>puntuation_count</th>\n",
              "      <th>polarity</th>\n",
              "      <th>POS_tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>[(father, RBR), (dysfunctional, JJ), (selfish,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks lyft credit cannot use cause offer whee...</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>[(thanks, NNS), (lyft, VBP), (credit, NN), (ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday majesty</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>[(bihday, NN), (majesty, NN)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take time ur!!!</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0.976562</td>\n",
              "      <td>[(model, NN), (love, VB), (take, NN), (time, N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society motivation</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>[(factsguide, NN), (:, :), (society, NN), (mot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate isz youuu?</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>[(ate, NN), (isz, NN), (youuu, NN), (?, .)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>see nina turner airwaves trying wrap mantle ge...</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>[(see, VB), (nina, JJ), (turner, NN), (airwave...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening sad songs monday morning otw work sad</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>[(listening, VBG), (sad, JJ), (songs, NNS), (m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>sikh temple vandalised calgary, wso condemns act</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>[(sikh, JJ), (temple, NNS), (vandalised, VBD),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank follow</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>[(thank, NN), (follow, NN)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                         POS_tagged\n",
              "0          0  ...  [(father, RBR), (dysfunctional, JJ), (selfish,...\n",
              "1          0  ...  [(thanks, NNS), (lyft, VBP), (credit, NN), (ca...\n",
              "2          0  ...                      [(bihday, NN), (majesty, NN)]\n",
              "3          0  ...  [(model, NN), (love, VB), (take, NN), (time, N...\n",
              "4          0  ...  [(factsguide, NN), (:, :), (society, NN), (mot...\n",
              "...      ...  ...                                                ...\n",
              "31957      0  ...        [(ate, NN), (isz, NN), (youuu, NN), (?, .)]\n",
              "31958      0  ...  [(see, VB), (nina, JJ), (turner, NN), (airwave...\n",
              "31959      0  ...  [(listening, VBG), (sad, JJ), (songs, NNS), (m...\n",
              "31960      1  ...  [(sikh, JJ), (temple, NNS), (vandalised, VBD),...\n",
              "31961      0  ...                        [(thank, NN), (follow, NN)]\n",
              "\n",
              "[31962 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtQW_wW4TaxL"
      },
      "source": [
        "Converting all POS tags to a sentence form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F849gdwvJ-CF"
      },
      "source": [
        "def sepPOS(text):\n",
        "    keep = []\n",
        "    for tup in text:\n",
        "        keep.append(tup[1])\n",
        "\n",
        "    tags = ' '.join(keep)\n",
        "    return tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSV2JHhfJ-CF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "69d06cb1-b020-41fc-c3d7-49112f93ada9"
      },
      "source": [
        "df['POS_tagged'] = df['POS_tagged'].apply(sepPOS)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>word_count</th>\n",
              "      <th>unique_words_count</th>\n",
              "      <th>puntuation_count</th>\n",
              "      <th>polarity</th>\n",
              "      <th>POS_tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>RBR JJ JJ NNS NNS NN . VB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks lyft credit cannot use cause offer whee...</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>NNS VBP NN MD RB VB NN NN NN NNS VBP . VBN VBD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday majesty</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NN NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take time ur!!!</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0.976562</td>\n",
              "      <td>NN VB NN NN JJ . . .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society motivation</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NN : NN NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate isz youuu?</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NN NN NN .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>see nina turner airwaves trying wrap mantle ge...</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>VB JJ NN NNS VBG NN FW JJ NN IN NN NN . NN NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening sad songs monday morning otw work sad</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>VBG JJ NNS JJ NN NN NN NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>sikh temple vandalised calgary, wso condemns act</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>JJ NNS VBD JJ , JJ NN NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank follow</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NN NN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                      POS_tagged\n",
              "0          0  ...                       RBR JJ JJ NNS NNS NN . VB\n",
              "1          0  ...  NNS VBP NN MD RB VB NN NN NN NNS VBP . VBN VBD\n",
              "2          0  ...                                           NN NN\n",
              "3          0  ...                            NN VB NN NN JJ . . .\n",
              "4          0  ...                                      NN : NN NN\n",
              "...      ...  ...                                             ...\n",
              "31957      0  ...                                      NN NN NN .\n",
              "31958      0  ...   VB JJ NN NNS VBG NN FW JJ NN IN NN NN . NN NN\n",
              "31959      0  ...                       VBG JJ NNS JJ NN NN NN NN\n",
              "31960      1  ...                        JJ NNS VBD JJ , JJ NN NN\n",
              "31961      0  ...                                           NN NN\n",
              "\n",
              "[31962 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZN3O6lAThTC"
      },
      "source": [
        "Downloading word2vec pretrained model 'glove-wiki-gigaword-300' and using it to calculate cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aJlHjB5DmQQ"
      },
      "source": [
        "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-300')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucGjnOQiHSGX"
      },
      "source": [
        "def similarity(sen1,sen2):\n",
        "    new=\"\"\n",
        "    for word in sen1.split():\n",
        "        if(word) in glove_vectors.vocab:\n",
        "            new= new + \" \" + word\n",
        "    if(len(new)) < 1:\n",
        "        new = \";\"\n",
        "    sim = glove_vectors.wv.n_similarity(new.split(),sen2.split())\n",
        "    return sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhs5Uf3OTsGa"
      },
      "source": [
        "List of hate speech words. These are taken out manually from our train data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "id": "gly_fS8XD5jH",
        "outputId": "e6af5c06-189a-47f0-9f68-28a089162d27"
      },
      "source": [
        "hate_speech = \"fight xenophobia people black supremacy racism fuck bitch jewish trash prejudice leftist jew trump mock racist fake sex evil violation genocide leftist zionism capitalism communist islamic extremists islam nude nigger nigga nazis\"\n",
        "df['cosine_similarity'] = df['cleaned'].apply(lambda x: similarity(x, hate_speech))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>word_count</th>\n",
              "      <th>unique_words_count</th>\n",
              "      <th>puntuation_count</th>\n",
              "      <th>polarity</th>\n",
              "      <th>POS_tagged</th>\n",
              "      <th>cosine_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>RBR JJ JJ NNS NNS NN . VB</td>\n",
              "      <td>0.344959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks lyft credit cannot use cause offer whee...</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>NNS VBP NN MD RB VB NN NN NN NNS VBP . VBN VBD</td>\n",
              "      <td>0.305413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday majesty</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NN NN</td>\n",
              "      <td>0.024043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take time ur!!!</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0.976562</td>\n",
              "      <td>NN VB NN NN JJ . . .</td>\n",
              "      <td>0.402271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society motivation</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NN : NN NN</td>\n",
              "      <td>0.414747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>ate isz youuu?</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NN NN NN .</td>\n",
              "      <td>0.083354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>see nina turner airwaves trying wrap mantle ge...</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>VB JJ NN NNS VBG NN FW JJ NN IN NN NN . NN NN</td>\n",
              "      <td>0.430588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening sad songs monday morning otw work sad</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>VBG JJ NNS JJ NN NN NN NN</td>\n",
              "      <td>0.285831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>sikh temple vandalised calgary, wso condemns act</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>JJ NNS VBD JJ , JJ NN NN</td>\n",
              "      <td>0.383867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank follow</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NN NN</td>\n",
              "      <td>0.271685</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ... cosine_similarity\n",
              "0          0  ...          0.344959\n",
              "1          0  ...          0.305413\n",
              "2          0  ...          0.024043\n",
              "3          0  ...          0.402271\n",
              "4          0  ...          0.414747\n",
              "...      ...  ...               ...\n",
              "31957      0  ...          0.083354\n",
              "31958      0  ...          0.430588\n",
              "31959      0  ...          0.285831\n",
              "31960      1  ...          0.383867\n",
              "31961      0  ...          0.271685\n",
              "\n",
              "[31962 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FM-k_M9J-CF"
      },
      "source": [
        "_________________________________________________________________________________________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeEANl7mJ-CF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[['cleaned', 'word_count', 'unique_words_count', 'POS_tagged', 'puntuation_count', 'polarity']], df['label'], random_state = 1, train_size = 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnXxsr1-J-CF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "adda0745-3ece-49cd-a52b-cce94ec8d025"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned</th>\n",
              "      <th>word_count</th>\n",
              "      <th>unique_words_count</th>\n",
              "      <th>POS_tagged</th>\n",
              "      <th>puntuation_count</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2051</th>\n",
              "      <td>females worry good niggaz take good care den kids</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>NNS VBP JJ NNS VBP JJ NN JJ NNS</td>\n",
              "      <td>0</td>\n",
              "      <td>0.70000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20151</th>\n",
              "      <td>euro2016 marseille england russia france tearg...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>NN NNS VBP JJ NN NN NNS VBP NN , JJ NN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6595</th>\n",
              "      <td>ego, suppose? happening \"me\" happening..</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>NN , VB . VBG `` PRP '' NN</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8676</th>\n",
              "      <td>love puppy labicha yelbicho model puppy barcel...</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>VB JJ NN NN NN JJ NN NN NN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13588</th>\n",
              "      <td>lighttherapy help depression? altwaystoheal he...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>NN NN NN . JJ JJ JJ . .</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17289</th>\n",
              "      <td>remember lost empire dreams success goals aim ...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>VB VBN NN NN NN NNS VBP NN NN NN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5192</th>\n",
              "      <td>justice served bosmatrial</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NN VBD JJ</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12172</th>\n",
              "      <td>repurposed former mustard jar beaut little vas...</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>VBN JJ NN NN NN JJ JJ NN NN</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.09375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>happiest baby ever known cute smiles babygirl ...</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>NN NN RB VBN NN NNS VBP JJ RB VBD NN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.67500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29733</th>\n",
              "      <td>ased bull up: dominate bull direct whatever wa...</td>\n",
              "      <td>21</td>\n",
              "      <td>15</td>\n",
              "      <td>VBN NN IN : JJ NN JJ WDT VBP VBP .</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25569 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 cleaned  ...  polarity\n",
              "2051   females worry good niggaz take good care den kids  ...   0.70000\n",
              "20151  euro2016 marseille england russia france tearg...  ...   0.00000\n",
              "6595            ego, suppose? happening \"me\" happening..  ...   0.00000\n",
              "8676   love puppy labicha yelbicho model puppy barcel...  ...   0.50000\n",
              "13588  lighttherapy help depression? altwaystoheal he...  ...   0.75000\n",
              "...                                                  ...  ...       ...\n",
              "17289  remember lost empire dreams success goals aim ...  ...   0.30000\n",
              "5192                           justice served bosmatrial  ...   0.00000\n",
              "12172  repurposed former mustard jar beaut little vas...  ...  -0.09375\n",
              "235    happiest baby ever known cute smiles babygirl ...  ...   0.67500\n",
              "29733  ased bull up: dominate bull direct whatever wa...  ...   0.10000\n",
              "\n",
              "[25569 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TezhgWBwJ-CF"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "mapper = DataFrameMapper([\n",
        "    (['word_count', 'unique_words_count', 'puntuation_count'], None),\n",
        "    ('cleaned',CountVectorizer()),\n",
        "    ('POS_tagged', CountVectorizer())\n",
        "])\n",
        "train1 = mapper.fit_transform(x_train)\n",
        "test1 = mapper.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13oxrhzgBILh"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "mapper = DataFrameMapper([\n",
        "    (['word_count', 'unique_words_count', 'puntuation_count', 'polarity'], None),\n",
        "    ('cleaned',TfidfVectorizer()),\n",
        "    ('POS_tagged', TfidfVectorizer())\n",
        "])\n",
        "train2 = mapper.fit_transform(x_train)\n",
        "test2 = mapper.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttme-XaW35xT",
        "outputId": "78759fe8-c835-453a-efa5-4e3ed82dc39b"
      },
      "source": [
        "train1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25569, 33801)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7W7ffhDVbid",
        "outputId": "b3e567fc-9008-4728-c26b-cc03b9e40858"
      },
      "source": [
        "train2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25569, 33802)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSBmVqLgT8DC"
      },
      "source": [
        "Naive Bayes (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uUligM-HbPq",
        "outputId": "03f7c2a1-fdea-4a4e-fffe-851a73bafede"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nv = MultinomialNB()\n",
        "nv.fit(train1, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEtDcE-EILL-"
      },
      "source": [
        "pred_nb = nv.predict(test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wov1jDibIfYY",
        "outputId": "5d8c2ade-486b-4068-9cf2-f91d52f55d3b"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('Accuracy score: ', format(accuracy_score(y_test, pred_nb)))\n",
        "print('Precision score: ', format(precision_score(y_test, pred_nb)))\n",
        "print('Recall score: ', format(recall_score(y_test, pred_nb)))\n",
        "print('F1 score: ', format(f1_score(y_test, pred_nb)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.9505709369623025\n",
            "Precision score:  0.9915966386554622\n",
            "Recall score:  0.27251732101616627\n",
            "F1 score:  0.427536231884058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJhEWmNtUCTr"
      },
      "source": [
        "linearSVC (1st Approach)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDqKJXnj9ltk",
        "outputId": "e4dbf9f3-a0ca-4bea-a8bf-dd485ceeb28e"
      },
      "source": [
        "from sklearn import svm\n",
        "lin_clf = svm.LinearSVC(max_iter=10000)\n",
        "lin_clf.fit(train2, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXIuWRhZC3cC"
      },
      "source": [
        "pred_svc = lin_clf.predict(test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mOKPfpODKkh",
        "outputId": "5d938cfa-d725-4887-9fb1-2ec3aa576190"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('Accuracy score: ', format(accuracy_score(y_test, pred_svc)))\n",
        "print('Precision score: ', format(precision_score(y_test, pred_svc)))\n",
        "print('Recall score: ', format(recall_score(y_test, pred_svc)))\n",
        "print('F1 score: ', format(f1_score(y_test, pred_svc)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.9643359924917879\n",
            "Precision score:  0.8317152103559871\n",
            "Recall score:  0.5935334872979214\n",
            "F1 score:  0.692722371967655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8tFmopP4sID"
      },
      "source": [
        "# Deep learning/Neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN0b5AmV41Pl"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1udrPPN_6yMl"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['cleaned'], df['label'], random_state = 1, train_size = 0.85)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r83Xc7cB9AzH",
        "outputId": "b48bf359-1bc6-455a-b9dd-4ba9ab54d205"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    25264\n",
              "1     1903\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NXbbiv5CDnv"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to integers\n",
        "\n",
        "# ENCODE Spanish source sentences\n",
        "tok = Tokenizer(lower=False) \n",
        "tok.fit_on_texts(x_train)\n",
        "\n",
        "x_train = tok.texts_to_sequences(x_train) # encode the train data into integers\n",
        "\n",
        "x_test = tok.texts_to_sequences(x_test) # encode the test data into integers\n",
        "\n",
        "total_words = len(tok.word_index) + 1   # adding 1 because of 0 padding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PrmNAJL5zIL"
      },
      "source": [
        "max_features = 30000  # Only consider the top 30k words\n",
        "maxlen = 100  # Only consider the first 100 words of each tweet\n",
        "EMBEDDING_SIZE=32\n",
        "VOCAB_SIZE=total_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3qy0AYm46Iq",
        "outputId": "f7798e46-eb9b-4f74-8d0d-fed9aaa10ff6"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Softmax, Dropout, Activation\n",
        "from keras.layers import SimpleRNN, LSTM, Embedding, Bidirectional\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(VOCAB_SIZE, EMBEDDING_SIZE, input_length=100))\n",
        "model.add(Bidirectional(SimpleRNN(25), merge_mode='concat'))\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "model.add(Dropout(0.2)) #Adding dropout of 0.2\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 32)           1142432   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 50)                2900      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 102       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 6         \n",
            "=================================================================\n",
            "Total params: 1,145,440\n",
            "Trainable params: 1,145,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7NqoaYD9xaw"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen, value=0, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen, value=0, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4Qnbe5KUYhy"
      },
      "source": [
        "Adding Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ch4_-mONDdS",
        "outputId": "592f3cea-84e9-4ace-d106-ad5b4c8cf900"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "callback = EarlyStopping(monitor='loss', patience=5)\n",
        "bi_history = model.fit(x_train, to_categorical(y_train), epochs=50, validation_split=0.10, callbacks = [callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "765/765 [==============================] - 106s 138ms/step - loss: 0.0709 - accuracy: 0.9627 - precision: 0.9627 - recall: 0.9627 - val_loss: 0.3254 - val_accuracy: 0.9382 - val_precision: 0.9382 - val_recall: 0.9382\n",
            "Epoch 2/50\n",
            "765/765 [==============================] - 106s 138ms/step - loss: 0.0697 - accuracy: 0.9625 - precision: 0.9625 - recall: 0.9625 - val_loss: 0.3221 - val_accuracy: 0.9260 - val_precision: 0.9257 - val_recall: 0.9260\n",
            "Epoch 3/50\n",
            "765/765 [==============================] - 105s 137ms/step - loss: 0.0706 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - val_loss: 0.3285 - val_accuracy: 0.9194 - val_precision: 0.9194 - val_recall: 0.9194\n",
            "Epoch 4/50\n",
            "765/765 [==============================] - 107s 139ms/step - loss: 0.0704 - accuracy: 0.9617 - precision: 0.9617 - recall: 0.9617 - val_loss: 0.3521 - val_accuracy: 0.9396 - val_precision: 0.9396 - val_recall: 0.9396\n",
            "Epoch 5/50\n",
            "765/765 [==============================] - 108s 141ms/step - loss: 0.0694 - accuracy: 0.9630 - precision: 0.9630 - recall: 0.9630 - val_loss: 0.3951 - val_accuracy: 0.9404 - val_precision: 0.9404 - val_recall: 0.9404\n",
            "Epoch 6/50\n",
            "765/765 [==============================] - 107s 140ms/step - loss: 0.0696 - accuracy: 0.9629 - precision: 0.9629 - recall: 0.9629 - val_loss: 0.3409 - val_accuracy: 0.9260 - val_precision: 0.9260 - val_recall: 0.9260\n",
            "Epoch 7/50\n",
            "765/765 [==============================] - 107s 140ms/step - loss: 0.0683 - accuracy: 0.9636 - precision: 0.9636 - recall: 0.9636 - val_loss: 0.3740 - val_accuracy: 0.9308 - val_precision: 0.9308 - val_recall: 0.9308\n",
            "Epoch 8/50\n",
            "765/765 [==============================] - 108s 141ms/step - loss: 0.0701 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - val_loss: 0.3893 - val_accuracy: 0.9282 - val_precision: 0.9282 - val_recall: 0.9282\n",
            "Epoch 9/50\n",
            "765/765 [==============================] - 108s 141ms/step - loss: 0.0728 - accuracy: 0.9596 - precision: 0.9596 - recall: 0.9596 - val_loss: 0.3831 - val_accuracy: 0.9308 - val_precision: 0.9308 - val_recall: 0.9308\n",
            "Epoch 10/50\n",
            "765/765 [==============================] - 110s 144ms/step - loss: 0.0684 - accuracy: 0.9636 - precision: 0.9636 - recall: 0.9636 - val_loss: 0.3967 - val_accuracy: 0.9326 - val_precision: 0.9327 - val_recall: 0.9330\n",
            "Epoch 11/50\n",
            "765/765 [==============================] - 109s 143ms/step - loss: 0.0708 - accuracy: 0.9613 - precision: 0.9613 - recall: 0.9613 - val_loss: 0.4112 - val_accuracy: 0.9293 - val_precision: 0.9293 - val_recall: 0.9293\n",
            "Epoch 12/50\n",
            "765/765 [==============================] - 111s 145ms/step - loss: 0.0686 - accuracy: 0.9633 - precision: 0.9633 - recall: 0.9633 - val_loss: 0.3982 - val_accuracy: 0.9319 - val_precision: 0.9316 - val_recall: 0.9319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwpFIAkYM-ba",
        "outputId": "84fab2d4-16e4-4b75-f346-ebb746018237"
      },
      "source": [
        "loss, acc, precision, recall = model.evaluate(x_test, to_categorical(y_test))\n",
        "print(\"Test accuracy: %0.2f%%\"%(acc*100))\n",
        "print(\"Test precision: %0.2f%%\"%(precision*100))\n",
        "print(\"Test recall: %0.2f%%\"%(recall*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 2s 16ms/step - loss: 0.3856 - accuracy: 0.9449 - precision: 0.9449 - recall: 0.9449\n",
            "Test accuracy: 94.49%\n",
            "Test precision: 94.49%\n",
            "Test recall: 94.49%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}